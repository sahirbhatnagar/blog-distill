---
title: "cv-errors"
description: |
  A short description of the post.
author:
  - name: Sahir Bhatnagar
    url: https://sahirbhatnagar.com/blog
date: 2021-11-12
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Simulation function -- response is a quadratic function of continuous predictor


```{r}
sim_quadratic_logistic_data = function(sample_size = 25) {
  x = rnorm(n = sample_size)
  eta = -1.5 + 0.5 * x + x ^ 2 + rnorm(sample_size, sd = 2) # add some noise
  p = 1 / (1 + exp(-eta))
  y = rbinom(n = sample_size, size = 1, prob = p)
  data.frame(y.factor = factor(y, levels = 1:0, labels = c("COPD","control")), x = x, y = y)
}
```

# Fit once to see what the resulting predicted curve looks like

```{r}
set.seed(42)
example_data <- sim_quadratic_logistic_data(sample_size = 500)
table(example_data$y.factor)

fit_glm <- glm(y ~ x + I(x^2), data = example_data, family = binomial)
summary(fit_glm)

plot(y ~ x, data = example_data,
     pch = 20, ylab = "Estimated Probability",
     main = "Logistic Regression, Quadratic Relationship")
grid()
curve(predict(fit_glm, data.frame(x), type = "response"),
      add = TRUE, col = "dodgerblue", lty = 2)
curve(boot::inv.logit(-1.5 + 0.5 * x + x ^ 2),
      add = TRUE, col = "darkorange", lty = 1)
legend("bottomleft", c("True Probability", "Estimated Probability", "Data"), lty = c(1, 2, 0),
       pch = c(NA, NA, 20), lwd = 2, col = c("darkorange", "dodgerblue", "black"))
```


# Run cross-validation experiment once

```{r}
if(!requireNamespace("pacman")) install.packages("pacman")
pacman::p_load(caret)
pacman::p_load(MLmetrics)
pacman::p_load(dplyr)
pacman::p_load(tidyr)

# function that returns the metrics of interest
MySummary <- function (data, lev = NULL, model = NULL) {
  
  PPV = caret::posPredValue(data = data$pred,
                            reference = data$obs)
  NPV = caret::negPredValue(data = data$pred,
                            reference = data$obs)

  tt <- table(data$pred, data$obs)
  n_call_COPD <- sum(tt[1,]) # number of 'positives' called by the model
  n_call_control <- sum(tt[2,]) # number of 'negatives' called by the model

  c(PPV = PPV,
    NPV = NPV,
    Macro = (PPV + NPV) / 2, # JH calls this ave.suuccess12
    SE2_Macro =  (1/2^2) * (PPV * (1-PPV) / n_call_COPD + NPV * (1-NPV) / n_call_control) # JH calls this var.ave.success
  )
}
```



```{r, warning=FALSE}
set.seed(42)

# sample size
N <- 500

# folds 
K <- 5

# simulate data
df <- sim_quadratic_logistic_data(sample_size = N)

# fit the model with cross-validated metrics
fit <- caret::train(y.factor ~ x + I(x^2),
                    data = df,
                    method = "glm",
                    family = "binomial",
                    trControl = trainControl(method = "cv",
                                             number = K,
                                             savePredictions = TRUE,
                                             summaryFunction = MySummary,
                                             classProbs = TRUE))

knitr::kable(fit$resample)
```



# Run CV experiment many times

```{r, echo=TRUE, warning=FALSE}
set.seed(42)
n.samples <- 400 # number of replications

# sample size
N <- 500

# folds 
K <- 5

# repeat experiment several times
res.list <- replicate(n.samples, expr = {

  # simulate data
  df <- sim_quadratic_logistic_data(sample_size = N)
  
  # fit the model with cross-validated metrics
  fit <- caret::train(y.factor ~ x + I(x^2),
                      data = df,
                      method = "glm",
                      family = "binomial",
                      trControl = trainControl(method = "cv",
                                               number = K,
                                               savePredictions = TRUE,
                                               summaryFunction = MySummary,
                                               classProbs = TRUE))
  data.frame(
    SE_pbar = (1/K)*sqrt(mean(fit$resample$SE2_Macro)), # model based (what the reviewer suggested)
    SEM = sd(fit$resample$Macro) / sqrt(K), # what we did aka the Standard error of the mean
    corr_ppv_npv = cor(fit$resample$PPV, fit$resample$NPV)
  )

}, simplify = FALSE)


res <- do.call(rbind, res.list) %>% 
  mutate(replicate = 1:n())

hist(res$corr_ppv_npv, 
     col = "lightblue", 
     xlab = "corr(PPV, NPV)",
     main = sprintf("Average correlation(PPV, NPV) over %i samples = %0.2f",n.samples, mean(res$corr_ppv_npv)))


res %>% 
  dplyr::select(replicate, SE_pbar, SEM) %>% 
  tidyr::pivot_longer(cols = -1, names_to = "SE_type") %>% 
  ggplot(aes(x = SE_type, y = value)) + geom_boxplot() + 
  labs(title = "Distribution of standard errors for SEM vs. Average of \nK fold model based variances over many replications")

boxplot(res$SEM / res$SE_pbar, main = "Ratio of SEM to SE_pbar")

```




# Run CV Experiment over increasing K and N

```{r, eval=FALSE, echo=TRUE}
set.seed(42)
n.samples <- 500  # number of replications

library(purrr)


cv_fun <- function(N, K){
  # repeat experiment several times
  res.list <- replicate(n.samples, expr = {
    
    # simulate data
    df <- sim_quadratic_logistic_data(sample_size = N)
    
    # fit the model with cross-validated metrics
    fit <- caret::train(y.factor ~ x + I(x^2),
                        data = df,
                        method = "glm",
                        family = "binomial",
                        trControl = trainControl(method = "cv",
                                                 number = K,
                                                 savePredictions = TRUE,
                                                 summaryFunction = MySummary,
                                                 classProbs = TRUE))
    data.frame(
      N = N,
      K = K,
      SE_pbar = sqrt((1/K)*mean(fit$resample$SE2_Macro)), # model based (what the reviewer suggested)
      SEM = sd(fit$resample$Macro) / sqrt(K), # what we did aka the Standard error of the mean
      corr_ppv_npv = cor(fit$resample$PPV, fit$resample$NPV)
    )
    
  }, simplify = FALSE)
  
  do.call(rbind, res.list) %>% 
    mutate(replicate = 1:n())
}


params <- expand.grid(N = c(100, 250, 500, 1000, 5000),
                      K = c(5, 10, 20))

tt <- map2_dfr(.x = params$N, 
               .y = params$K, 
               .f = cv_fun)
```


```{r}
# saveRDS(tt, file = "N_K_cv_fun.rds")
tt <- readRDS(file = "N_K_cv_fun.rds")
library(tidyverse)
library(ggridges)


# pdf(file = "~/Dropbox/mcgill/radiology/peter/varying_N_K.pdf", width = 11, height = 9)
tt %>% 
  mutate(replicate = 1:n()) %>% 
  tidyr::pivot_longer(cols = -c(N,K,replicate), names_to = "SE_type") %>% 
  dplyr::filter(SE_type != "corr_ppv_npv") %>% 
  ggplot(mapping = aes(y = SE_type, x = value)) +
  geom_density_ridges(scale = 0.9) + 
  # stat_density_ridges() + 
  facet_grid(N ~ K, scales = "free") + 
  labs(title = "Distribution of standard errors for SEM vs. Average of \nK fold model based variances over 500 replications", 
       subtitle = "Columns are number of folds (K) and rows are sample size (N)") + 
  ggthemes::theme_stata() + cowplot::panel_border()
# dev.off()  



# pdf(file = "~/Dropbox/mcgill/radiology/peter/varying_N_K_correlation.pdf", width = 11, height = 9)
tt %>% 
  mutate(replicate = 1:n()) %>% 
  tidyr::pivot_longer(cols = -c(N,K,replicate), names_to = "SE_type") %>% 
  dplyr::filter(SE_type == "corr_ppv_npv") %>% 
  ggplot(mapping = aes(y = SE_type, x = value)) +
  geom_density_ridges(scale = 0.9) + 
  # stat_density_ridges() + 
  facet_grid(N ~ K, scales = "free") + 
  labs(title = "Distribution of correlation between PPV and NPV over 500 replications", 
       subtitle = "Columns are number of folds (K) and rows are sample size (N)") + 
  ggthemes::theme_stata() + cowplot::panel_border()
# dev.off()  

```
  
  
